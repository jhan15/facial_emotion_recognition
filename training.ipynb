{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"training.ipynb","provenance":[{"file_id":"1muoOaBA21nwc1MUlwEDcVyqAuoa5_AYu","timestamp":1623599622276}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PJPo8IwUvDCs"},"source":["# **Setup**"]},{"cell_type":"code","metadata":{"id":"TF6tceinbqKY"},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","    raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fIyEWviCB-tU"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VPlyEm18uWGc"},"source":["import numpy as np\n","import pickle\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import SMOTE\n","import collections\n","\n","from tensorflow.keras import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten, Activation\n","from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.initializers import HeNormal"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31IQz--Ur0LC"},"source":["# **Load data**"]},{"cell_type":"code","metadata":{"id":"lxQ45oIoKwlc"},"source":["# dataset is saved in my google drive\n","%cp -av \"/content/gdrive/MyDrive/loopQ/project\" \"/content\"\n","%cd /content/project/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ulCGo1gsJE0"},"source":["def load_data(data_file):\n","    print('Loading data ...')\n","    with open(data_file, 'rb') as f:\n","        pickle_data = pickle.load(f)\n","        x_data = pickle_data['x_data']\n","        y_data = pickle_data['y_data']\n","    print('Data loaded.')\n","    return x_data, y_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YeQNswnjAOud"},"source":["data_file = 'data/train_data.p'\n","images, labels = load_data(data_file)\n","\n","n_samples = labels.shape[0]\n","print('Total samples:', n_samples)\n","print('images shape:', images.shape)\n","print('labels shape:', labels.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lg_CoJejAdw2"},"source":["# **Explore data**"]},{"cell_type":"code","metadata":{"id":"E2wWgnggQOpk"},"source":["emotions = {\n","    0: 'Angry',\n","    1: 'Disgust',\n","    2: 'Fear',\n","    3: 'Happy',\n","    4: 'Sad',\n","    5: 'Surprise',\n","    6: 'Neutral'\n","}\n","\n","num_classes = len(emotions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hbp620-5nsmV"},"source":["def plot_sample_distribution(labels):\n","    classes, cnts = np.unique(labels, return_counts=True)\n","    plt.figure(figsize=(12, 5))\n","    plt.barh(list(emotions.values()), cnts, height=0.6)\n","    for i, v in enumerate(cnts):\n","        plt.text(v, i, ' '+str(v), va='center')\n","    plt.xlabel('Counts')\n","    plt.title(\"Distribution of samples\")\n","\n","plot_sample_distribution(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ITStB_q-NxAW"},"source":["def show_images(images, labels, col=5):\n","    n = images.shape[0]\n","    row = np.ceil(n / col)\n","    fig = plt.figure(figsize=(2*col, 2*row))\n","    for i in range(n):\n","        fig.add_subplot(row, col, i+1)\n","        plt.imshow(images[i], cmap='gray')\n","        plt.title(emotions[labels[i]])\n","        plt.xticks([]), plt.yticks([])\n","    plt.show()\n","\n","show_images(images[:25], labels[:25])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZtGD3AIGTDJ"},"source":["def show_one_emotion(images, labels, id, start=0, num=25):\n","    image_x = images[labels==id]\n","    label_x = labels[labels==id]\n","    show_images(image_x[start:start+num], label_x[start:start+num])\n","\n","show_one_emotion(images, labels, id=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jg0VHgt7AGvM"},"source":["# **Split dataset**"]},{"cell_type":"code","metadata":{"id":"1gBzBGUVi7s_"},"source":["image_train, image_test, label_train, label_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n","image_train, image_val, label_train, label_val = train_test_split(image_train, label_train, test_size=0.2, random_state=42)\n","\n","print('Training samples:', label_train.shape[0])\n","print('Validation samples:', label_val.shape[0])\n","print('Test samples:', label_test.shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zGA640ISNLOk"},"source":["# **Upsamling training data**"]},{"cell_type":"code","metadata":{"id":"ZCkKvXXRL8Gm"},"source":["def upsampling(x, y, strategy):\n","    (n, w, h) = x.shape\n","    sm = SMOTE(sampling_strategy=strategy, random_state=42)\n","    x_flat = x.reshape((n,-1))\n","    x_up, y_up = sm.fit_resample(x_flat, y)\n","    n_up = x_up.shape[0]\n","    x_up = x_up.reshape((n_up,w,h))\n","\n","    return x_up, y_up"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1AZ6DUeHMTMG"},"source":["collections.Counter(label_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U7J9NNf9EvOA"},"source":["image_train_up, label_train_up = upsampling(image_train, label_train, 'auto')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EEHlhWIdP5Xe"},"source":["collections.Counter(label_train_up)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WYA4C5IBRrkQ"},"source":["for i in range(num_classes):\n","    if i == 3:\n","        continue\n","    show_one_emotion(image_train_up, label_train_up, id=i, start=4000, num=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XGEwaXsbAP6M"},"source":["# **Utils**"]},{"cell_type":"code","metadata":{"id":"hXGSr3XNgLaU"},"source":["def one_hot_encoding(labels, num_classes):\n","    return tf.keras.utils.to_categorical(labels, num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QxxLhqRwz0__"},"source":["def reshape_images(images, channel=1, resize=None):\n","    x = tf.expand_dims(tf.convert_to_tensor(images), axis=3)\n","    if channel > 1:\n","        x = tf.repeat(x, channel, axis=3)\n","    if resize is not None:\n","        x = tf.image.resize(x, resize)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1lyreSTF2Kun"},"source":["def pre_processing(images, labels, num_classes, channel=1, resize=None, one_hot=True):\n","    x = reshape_images(images, channel, resize)\n","    y = one_hot_encoding(labels, num_classes)\n","    return x, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AS9SoasecWfJ"},"source":["def plot_metrics(history):\n","    metrics = ['loss', 'accuracy']\n","    plt.figure(figsize=(15, 6))\n","    plt.rc('font', size=12)\n","    for n, metric in enumerate(metrics):\n","        name = metric.capitalize()\n","        plt.subplot(1,2,n+1)\n","        plt.plot(history.epoch, history.history[metric], label='Training', lw=3, color='navy')\n","        plt.plot(history.epoch, history.history['val_'+metric], lw=3, label='Validation', color='deeppink')\n","        plt.xlabel('Epoch')\n","        plt.ylabel(name)\n","        plt.title('Model '+name)\n","        plt.legend()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wPaNVRNTNYnk"},"source":["def evaluate_class(model, x_test, y_test):\n","    labels = np.argmax(y_test, axis=1)\n","    print('{:<15}Accuracy'.format('Emotion'))\n","    print('-'*23)\n","    for i in range(num_classes):\n","        x = x_test[labels==i]\n","        y = y_test[labels==i]\n","        loss, acc = model.evaluate(x,  y, verbose=0)\n","        print('{:<15}{:.1%}'.format(emotions[i], acc))\n","    print('-'*23)\n","    loss, acc = model.evaluate(x_test,  y_test, verbose=0)\n","    print('{:<15}{:.1%}'.format('Overall', acc))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hlKd4AUchUk-"},"source":["# **Model**"]},{"cell_type":"code","metadata":{"id":"rYiR3PFDJyeI"},"source":["def model_checkpoint_cb(file_path):\n","    return ModelCheckpoint(\n","        file_path, monitor='val_accuracy', mode='max',\n","        save_best_only=True, save_weights_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQsV328DFG0n"},"source":["x_train, y_train = pre_processing(image_train_up, label_train_up, num_classes)\n","x_val, y_val = pre_processing(image_val, label_val, num_classes)\n","x_test, y_test = pre_processing(image_test, label_test, num_classes)\n","\n","train_datagen = ImageDataGenerator(\n","    rotation_range=30,\n","    shear_range=0.2,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    zoom_range=0.1,\n","    horizontal_flip=True)\n","\n","val_datagen = ImageDataGenerator()\n","\n","batch_size = 128\n","train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\n","val_generator = val_datagen.flow(x_val, y_val)\n","\n","steps_per_epoch = train_generator.n // train_generator.batch_size\n","input_shape = x_train[0].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mi5mb--EXON4"},"source":["# one_batch = train_generator.next()\n","# one_batch_images = one_batch[0].reshape((128,48,48))\n","# one_batch_labels = np.argmax(one_batch[1], axis=1)\n","# show_images(one_batch_images[:25], one_batch_labels[:25])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2JaSYECtFIbP"},"source":["class VGGNet(Sequential):\n","    def __init__(self, input_shape, num_classes, checkpoint_path, lr=1e-3):\n","        super().__init__()\n","        self.add(Rescaling(1./255, input_shape=input_shape))\n","        self.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal'))\n","        self.add(BatchNormalization())\n","        self.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(MaxPool2D())\n","        self.add(Dropout(0.5))\n","\n","        self.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(MaxPool2D())\n","        self.add(Dropout(0.4))\n","\n","        self.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(MaxPool2D())\n","        self.add(Dropout(0.5))\n","\n","        self.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(MaxPool2D())\n","        self.add(Dropout(0.4))\n","\n","        self.add(Flatten())\n","        \n","        self.add(Dense(1024, activation='relu'))\n","        self.add(Dropout(0.5))\n","        self.add(Dense(256, activation='relu'))\n","\n","        self.add(Dense(num_classes, activation='softmax'))\n","\n","        self.compile(optimizer=Adam(learning_rate=lr),\n","                    loss=categorical_crossentropy,\n","                    metrics=['accuracy'])\n","        \n","        self.checkpoint_path = checkpoint_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t5KkjDh9lNZ1"},"source":["model = VGGNet(input_shape, num_classes, 'run/vggnet_up.h5')\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i51lMzDgFIk2"},"source":["epochs = 200\n","cp = model_checkpoint_cb(model.checkpoint_path)\n","lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_lr=1e-10)\n","es = EarlyStopping(monitor='val_loss', verbose=1, patience=20)\n","\n","history = model.fit(\n","        train_generator,\n","        steps_per_epoch=steps_per_epoch,\n","        epochs=epochs,\n","        validation_data=val_generator,\n","        callbacks=[lr, es, cp])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OclpQrhRnQLx"},"source":["plot_metrics(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3VxmDoE35GQV"},"source":["model.load_weights(model.checkpoint_path)\n","evaluate_class(model, x_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NmIEAUo0kTEg"},"source":["%cp /content/project/run/vggnet.h5 /content/gdrive/MyDrive/loopQ/project/saved_models"],"execution_count":null,"outputs":[]}]}